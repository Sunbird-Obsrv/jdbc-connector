env = "local"
spark.master= "local[*]"

kafka {
  producer = {
    broker-servers = "localhost:9092"
    compression = "snappy"
    max-request-size = 1000000 # 1MB
  }
  output = {
    connector = {
      failed.topic = "connector.failed"
      metric.topic = "connector.metrics"
    }
  }
}

jdbc {
  connection{
    retry = 1
    retryDelay = 10
  }
}

#dataset-registry config
postgres {
  host = localhost
  port = 5432
  maxConnections = 2
  user = "postgres"
  password = "postgres"
  database = "obsrv"
}

connector.version = "1.0.0"

drivers {
  mysql = "com.mysql.cj.jdbc.Driver"
  postgresql = "org.postgresql.Driver"
}

obsrv.encryption.key = "strong_encryption_key_to_encrypt"

# if limit is -1, max limit check is ignored
event.max.limit = -1

metrics {
  version = "1.0.0"
  topicName = "spark.stats"
}